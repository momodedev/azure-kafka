- name: Ensure Kafka configuration directory ownership
  file:
    path: "{{ kafka_workspace }}/config"
    state: directory
    owner: kafka
    group: kafka
    mode: "0755"

- name: Check for existing Kafka metadata
  stat:
    path: "{{ kafka_data_dir }}/meta.properties"
  register: kafka_meta_properties
  run_once: true

- name: Assign deterministic node id
  set_fact:
    kafka_node_id: "{{ groups['kafka'].index(inventory_hostname) + 1 }}"
  run_once: true
  delegate_to: localhost
  delegate_facts: true


- name: Derive advertised host for Kafka
  set_fact:
    kafka_advertised_host: "{{ ansible_host | default(hostvars[inventory_hostname].private_ip) | default(ansible_default_ipv4.address) }}"

- name: Validate kafka_advertised_host
  assert:
    that:
      - kafka_advertised_host is defined
      - kafka_advertised_host != ''
      - kafka_advertised_host != '0.0.0.0'
      - kafka_advertised_host != '127.0.0.1'
      - kafka_advertised_host is match('^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$')
    fail_msg: |
      FATAL: kafka_advertised_host is invalid: {{ kafka_advertised_host | default('UNDEFINED') }}
      ansible_host: {{ ansible_host | default('UNDEFINED') }}
      private_ip: {{ hostvars[inventory_hostname].private_ip | default('UNDEFINED') }}
      ansible_default_ipv4.address: {{ ansible_default_ipv4.address | default('UNDEFINED') }}
    success_msg: "kafka_advertised_host validated: {{ kafka_advertised_host }}"

- name: DEBUG - Show final kafka_advertised_host
  debug:
    msg: "Broker {{ inventory_hostname }} will advertise on {{ kafka_advertised_host }}"

- name: Configure Kafka KRaft server properties
  template:
    src: server.properties.j2
    dest: "{{ kafka_workspace }}/config/server.properties"
    owner: kafka
    group: kafka
    mode: "0644"
  become: yes

- name: Verify advertised.listeners in rendered config
  shell: grep "^advertised.listeners=" {{ kafka_workspace }}/config/server.properties
  register: advertised_check
  changed_when: false
  become: yes

- name: DEBUG - Show rendered advertised.listeners
  debug:
    var: advertised_check.stdout

- name: Fail if advertised.listeners contains 0.0.0.0 or is empty
  fail:
    msg: "ERROR: advertised.listeners is misconfigured: {{ advertised_check.stdout }}"
  when: >
    '0.0.0.0' in advertised_check.stdout or
    advertised_check.stdout is search('://:[0-9]+') or
    advertised_check.stdout == ''

- name: Configure Kafka KRaft server properties
  template:
    src: server.properties.j2
    dest: "{{ kafka_workspace }}/config/server.properties"
    owner: kafka
    group: kafka
    mode: "0644"

- name: Read existing cluster id when present
  slurp:
    src: "{{ kafka_data_dir }}/meta.properties"
  when: kafka_meta_properties.stat.exists
  register: kafka_meta_contents
  run_once: true

- name: Extract existing cluster id
  when: kafka_meta_properties.stat.exists
  set_fact:
    kafka_cluster_id: "{{ (kafka_meta_contents.content | b64decode).split('\n') | select('match', '^cluster.id=') | list | first | regex_replace('^cluster.id=', '') }}"
  run_once: true
  delegate_to: localhost
  delegate_facts: true

- name: Generate Kafka cluster UUID
  when: not kafka_meta_properties.stat.exists
  become_user: kafka
  command: "{{ kafka_workspace }}/bin/kafka-storage.sh random-uuid"
  register: kafka_cluster_uuid
  run_once: true

- name: Share generated cluster UUID
  when: not kafka_meta_properties.stat.exists
  set_fact:
    kafka_cluster_id: "{{ kafka_cluster_uuid.stdout | trim }}"
  run_once: true
  delegate_to: localhost
  delegate_facts: true

- name: Format Kafka storage directories
  become_user: kafka
  command: "{{ kafka_workspace }}/bin/kafka-storage.sh format --config {{ kafka_workspace }}/config/server.properties --cluster-id {{ hostvars['localhost']['kafka_cluster_id'] }} --ignore-formatted"

- name: Create Kafka systemd unit
  template:
    src: kafka.service.j2
    dest: /etc/systemd/system/kafka.service
    mode: "0644"

- name: Reload systemd and start Kafka broker
  systemd:
    name: kafka
    state: started
    enabled: true
    daemon_reload: true

- name: Wait for Kafka client listener
  wait_for:
    host: "{{ private_ip | default(ansible_default_ipv4.address) }}"
    port: "{{ kafka_client_port }}"
    delay: 5
    timeout: 60
    state: started
    msg: "Kafka client listener not available on {{ inventory_hostname }}"

- name: Wait for Kafka controller listener
  wait_for:
    host: "{{ private_ip | default(ansible_default_ipv4.address) }}"
    port: "{{ kafka_controller_port }}"
    delay: 5
    timeout: 60
    state: started
    msg: "Kafka controller listener not available on {{ inventory_hostname }}"

- name: Unpack Kafka exporter
  unarchive:
    src: "{{ kafka_exporter_download_url }}"
    dest: /opt
    remote_src: true
    creates: "/opt/kafka_exporter-{{ kafka_exporter_version }}.linux-amd64"

- name: Symlink Kafka exporter directory
  file:
    src: "/opt/kafka_exporter-{{ kafka_exporter_version }}.linux-amd64"
    dest: /opt/kafka-exporter
    state: link
    force: true

- name: Create Kafka exporter systemd unit
  template:
    src: kafka_exporter.service.j2
    dest: /etc/systemd/system/kafka_exporter.service
    mode: "0644"

- name: Reload systemd and start Kafka exporter
  systemd:
    name: kafka_exporter
    state: started
    enabled: true
    daemon_reload: true

- name: Wait for Kafka exporter endpoint
  wait_for:
    host: "{{ private_ip | default(ansible_default_ipv4.address) }}"
    port: "{{ kafka_exporter_port }}"
    delay: 5
    timeout: 30
    state: started
    msg: "Kafka exporter not reachable on {{ inventory_hostname }}"


---
# Kafka Installation Defaults

# KRaft Configuration
kafka_process_roles: "broker,controller"
kafka_node_id: 1  # Will be overridden by playbook
kafka_controller_port: 9093
kafka_client_port: 9092
kafka_external_port: 9094

# Storage
kafka_log_dirs: "/kafka-data"
kafka_workspace: "/opt/kafka"

# Controller Quorum
kafka_controller_quorum_voters: "1@172.16.1.4:9093,2@172.16.1.5:9093,3@172.16.1.6:9093"

# Replication
kafka_offsets_topic_replication_factor: 3
kafka_transaction_state_log_replication_factor: 3
kafka_transaction_state_log_min_isr: 2
kafka_default_replication_factor: 3
kafka_min_insync_replicas: 2

# Network
kafka_num_network_threads: 8
kafka_num_io_threads: 16
kafka_socket_send_buffer_bytes: 102400
kafka_socket_receive_buffer_bytes: 102400
kafka_socket_request_max_bytes: 104857600

# Log Retention
kafka_log_retention_hours: 168
kafka_log_segment_bytes: 1073741824
kafka_log_retention_check_interval_ms: 300000
